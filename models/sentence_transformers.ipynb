{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We gonna use 3 differentes models to test our data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### They are \n",
    "##### - multi-qa-distilbert-cos-v1 (SentenceTransformer)\n",
    "##### - sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 (SentenceTransformer)\n",
    "##### - cross-encoder/ms-marco-MiniLM-L-6-v2 (CrossEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vanderson/miniconda3/envs/bert/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "2024-09-27 14:42:18.765507: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-27 14:42:18.783584: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-27 14:42:18.789145: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-27 14:42:18.802702: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-27 14:42:19.762622: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/vanderson/miniconda3/envs/bert/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import CrossEncoder\n",
    "import torch\n",
    "model = SentenceTransformer(\"multi-qa-distilbert-cos-v1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o modelo sentence-transformers multilíngue\n",
    "model_LM = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_cross = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\", default_activation_function=torch.nn.Sigmoid(),max_length=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8022, 0.7465, 0.8904, 0.8691, 0.8514, 0.5310, 0.7641]])\n"
     ]
    }
   ],
   "source": [
    "##Using the first model (multi_qa) as the model is not trained in multilingual\n",
    "## and we want to use to portuguese phrases, i will have to translate to use this model\n",
    "passage_embeddings=model.encode([\n",
    "    \"cancelar consulta\",\n",
    "   \" cancelar uma consulta\",\n",
    "    \"Quero cancelar a consulta\",\n",
    "   \" Como faz para cancelar a consulta\",\n",
    "   \" Preciso cancelar a consulta\",\n",
    "    \"Gostaria de desmarcar a consulta\",\n",
    "   \" Como faço para cancelar a consulta que marquei\"\n",
    "])\n",
    "query_embedding=model.encode(\"quero cancelar minha consulta\")\n",
    "similarity=model.similarity(query_embedding,passage_embeddings)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9259, 0.9335, 0.9778, 0.9416, 0.9662, 0.9486, 0.9275]])\n"
     ]
    }
   ],
   "source": [
    "##As we can see, the scores values to english phrases are much higher\n",
    "passage_embeddings=model.encode([\n",
    "    \"cancel appointment\", \n",
    "    \"cancel an appointment\", \n",
    "    \"I want to cancel the appointment\", \n",
    "    \"How do I cancel the appointment\", \n",
    "    \"I need to cancel the appointment\", \n",
    "    \"I would like to cancel the appointment\", \n",
    "    \"How do I cancel the appointment I made\"\n",
    "])\n",
    "query_embedding=model.encode(\"I want to cancel my appointment\")\n",
    "similarity=model.similarity(query_embedding,passage_embeddings)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7247]])\n"
     ]
    }
   ],
   "source": [
    "### USING THE SECOND MODEL, MULTILINGUAL\n",
    "### Testing with portuguese phrases\n",
    "query_embedding=model_LM.encode(\"Quero cancelar uma consulta com o psicologo\")\n",
    "# Exemplo de uso com frases em português\n",
    "passage_embeddings=model_LM.encode([\n",
    "    \"Quero cassar uma consulta com o psicologo\"\n",
    "])\n",
    "similarity=model_LM.similarity(query_embedding,passage_embeddings)\n",
    "\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5216, 0.8320, 0.7826, 0.7398, 0.7807, 0.7398, 0.9449, 0.7662]])\n"
     ]
    }
   ],
   "source": [
    "#### For english phrases, we do not see much difference is scores\n",
    "query_embedding=model_LM.encode(\"I want to book an appointment\")\n",
    "passage_embeddings=model_LM.encode([\n",
    "\"book an appointment with a psychologist\",\n",
    "\"book an appointment\",\n",
    "\"how do I schedule an appointment\",\n",
    "\"how do I schedule an appointment with you\",\n",
    "\"I want to schedule an appointment with you\",\n",
    "\"how do I schedule an appointment with you\",\n",
    "\"How can I book an appointment\",\n",
    "\"Is it possible to schedule an appointment\"\n",
    "])\n",
    "similarity=model_LM.similarity(query_embedding,passage_embeddings)\n",
    "\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5282, 0.9095, 0.7804, 0.7978, 0.8564, 0.7978, 0.9507, 0.7263]])\n"
     ]
    }
   ],
   "source": [
    "### Lets compare the scores with the first model\n",
    "query_embedding=model.encode(\"I want to book an appointment\")\n",
    "passage_embeddings=model.encode([\n",
    "\"book an appointment with a psychologist\",\n",
    "\"book an appointment\",\n",
    "\"how do I schedule an appointment\",\n",
    "\"how do I schedule an appointment with you\",\n",
    "\"I want to schedule an appointment with you\",\n",
    "\"how do I schedule an appointment with you\",\n",
    "\"How can I book an appointment\",\n",
    "\"Is it possible to schedule an appointment\"\n",
    "])\n",
    "similarity=model.similarity(query_embedding,passage_embeddings)\n",
    "\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stsb roberta is a good model too\n",
    "from sentence_transformers import CrossEncoder\n",
    "import torch\n",
    "model_cross = CrossEncoder('cross-encoder/stsb-roberta-base', \n",
    "                           default_activation_function=torch.nn.Sigmoid(), \n",
    "                           max_length=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### the first model obtained higher scores for English sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81391525]\n"
     ]
    }
   ],
   "source": [
    "### Lets test the cross encoder model\n",
    "scores = model_cross.predict([\n",
    "    (\"como agendo uma consulta\", \"marcar uma consulta\")\n",
    "\n",
    "])\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This cross encoder model does not handle synonymous words very well, so it will not be very useful for data augmentation, since the intention is to expand the database with synonyms and similar words, maintaining the meaning of the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But, how cross encoder detect a high level of score with similar sentences, we are gonna use to detect duplicates or too similar phrases in our dataset, to avoid too much similar data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
