{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/vanderson/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/vanderson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "from googletrans import Translator\n",
    "\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### getting synonym\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonyms(word):\n",
    "    synsets = wordnet.synsets(word, lang='por')\n",
    "    synonyms = set()\n",
    "    for syn in synsets:\n",
    "        for lemma in syn.lemma_names('por'):\n",
    "            synonyms.add(lemma.replace('_', ' '))\n",
    "    synonyms.discard(word)\n",
    "    return list(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stop_words = {\n",
    "    \"a\", \"à\", \"ao\", \"aos\", \"aquela\", \"aquelas\", \"aquele\", \"aqueles\", \"aquilo\",\n",
    "    \"as\", \"até\", \"com\", \"como\", \"da\", \"das\", \"de\", \"dela\", \"dele\", \"deles\", \"demais\",\n",
    "    \"do\", \"dos\", \"e\", \"é\", \"em\", \"entre\", \"era\", \"eram\", \"essa\", \"essas\", \"esse\",\n",
    "    \"esses\", \"esta\", \"está\", \"estamos\", \"estão\", \"estas\", \"estava\", \"estavam\",\n",
    "    \"este\", \"estes\", \"eu\", \"já\", \"lhe\", \"lhe(s)\", \"lo\", \"mas\", \"me\", \"meu\", \"meus\",\n",
    "    \"menos\", \"mesmo\", \"mesmos\", \"muito\", \"muitos\", \"na\", \"nas\", \"nem\", \"no\", \"nos\",\n",
    "    \"nós\", \"não\", \"num\", \"numa\", \"o\",\"os\", \"ou\", \"para\", \"pela\", \"pelas\", \"pelo\",\n",
    "    \"pelos\", \"perante\", \"pois\", \"por\", \"porém\", \"sem\", \"seu\", \"seus\", \"só\", \"sob\",\n",
    "    \"sobre\", \"sua\", \"suas\", \"também\", \"te\", \"tem\", \"têm\", \"tenho\", \"ter\", \"teu\",\n",
    "    \"teus\", \"tu\", \"tua\", \"tuas\", \"tudo\", \"um\", \"uma\", \"uns\", \"umas\", \"você\",\n",
    "    \"vocês\", \"vos\", \"vós\", \"àquela\", \"àquelas\", \"aquele\", \"aqueles\", \"aquilo\",\n",
    "    \"aí\", \"ainda\", \"além\", \"algum\", \"alguma\", \"algumas\", \"alguns\", \"além\", \"alma\",\n",
    "    \"antes\", \"após\", \"assim\", \"atrás\", \"bem\", \"boa\", \"bons\", \"cabe\", \"certa\",\n",
    "    \"certas\", \"certo\", \"certos\", \"cidade\", \"cada\", \"cerca\", \"cima\", \"comigo\",\n",
    "    \"conforme\", \"consigo\", \"contra\", \"contudo\", \"daquela\", \"daquelas\", \"daquele\",\n",
    "    \"daqueles\", \"dela\", \"dele\", \"deles\", \"delas\", \"dentro\", \"desde\", \"dessa\",\n",
    "    \"dessas\", \"desse\", \"desses\", \"desta\", \"destas\", \"deste\", \"destes\", \"deste\",\n",
    "    \"deste\", \"dessas\", \"desses\", \"desde\", \"disso\", \"dito\", \"dizer\", \"do\", \"dói\",\n",
    "    \"dóis\", \"dois\", \"doravante\", \"duas\", \"durante\"\n",
    "}\n",
    "\n",
    "\n",
    "def sinonimo(phrase):\n",
    "    tokens = re.findall(r'\\b\\w+\\b|[^\\w\\s]', phrase, re.UNICODE)\n",
    "    new_tokens = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        # Verifica se o token é uma palavra (não pontuação)\n",
    "        if re.match(r'\\b\\w+\\b', token):\n",
    "            if token.lower() in stop_words:\n",
    "                new_tokens.append(token)\n",
    "            else:\n",
    "                synonyms = get_synonyms(token)\n",
    "                if synonyms:\n",
    "                    new_word = random.choice(synonyms)\n",
    "                    # Preserva a capitalização\n",
    "                    if token[0].isupper():\n",
    "                        new_word = new_word.capitalize()\n",
    "                    new_tokens.append(new_word)\n",
    "                else:\n",
    "                    new_tokens.append(token)\n",
    "        else:\n",
    "            new_tokens.append(token)\n",
    "    \n",
    "    return ''.join([\n",
    "        (' ' + token) if re.match(r'\\w', token) and i != 0 and re.match(r'\\w', new_tokens[i-1]) else token\n",
    "        for i, token in enumerate(new_tokens)\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insercao_noise(phrase):\n",
    "    words = phrase.split()\n",
    "    insert_idx = random.randint(0, len(words))\n",
    "    random_word = random.choice([ 'Casa', 'Carro', 'Computador', 'Livro', 'Árvore', 'Café', 'Amigo', 'Cidade', 'Escola', 'Relógio',\n",
    "    'Telefone', 'Janela', 'Cadeira', 'Mesa', 'Bicicleta', 'Praia', 'Montanha', 'Rio', 'Cachorro', 'Gato',\n",
    "    'Céu', 'Estrela', 'Flor', 'Pássaro', 'Noite', 'Dia', 'Sol', 'Lua', 'Chave', 'Porta',\n",
    "    'Sapato', 'Roupa', 'Caneta', 'Lápis', 'Papel', 'Foto', 'Brinquedo', 'Jogo', 'Chuva', 'Neve',\n",
    "    'Vento', 'Fogo', 'Terra', 'Mar', 'Avião', 'Navio', 'Trem', 'Ônibus', 'Mercado',\n",
    "\n",
    "    # Verbos\n",
    "    'Correr', 'Andar', 'Comer', 'Beber', 'Ler', 'Escrever', 'Dormir', 'Acordar', 'Falar', 'Ouvir',\n",
    "    'Ver', 'Assistir', 'Pensar', 'Sorrir', 'Rir', 'Chorar', 'Jogar', 'Brincar', 'Estudar', 'Trabalhar',\n",
    "    'Cantar', 'Dançar', 'Nadar', 'Viajar', 'Cozinhar', 'Limpar', 'Consertar', 'Construir', 'Destruir',\n",
    "    'Comprar', 'Vender', 'Pagar', 'Ganhar', 'Perder', 'Encontrar', 'Procurar', 'Esperar', 'Ajudar',\n",
    "    'Ensinar', 'Aprender',\n",
    "\n",
    "    # Adjetivos\n",
    "    'Bonito', 'Feio', 'Grande', 'Pequeno', 'Alto', 'Baixo', 'Rápido', 'Lento', 'Feliz', 'Triste',\n",
    "    'Calmo', 'Agitado', 'Doce', 'Amargo', 'Quente', 'Frio', 'Claro', 'Escuro', 'Novo', 'Velho',\n",
    "    'Forte', 'Fraco', 'Inteligente', 'Bobo', 'Gentil', 'Cruel', 'Simpático', 'Antipático',\n",
    "    'Interessante', 'Entediante',\n",
    "\n",
    "    # Advérbios\n",
    "    'Rapidamente', 'Devagar', 'Hoje', 'Amanhã', 'Ontem', 'Sempre', 'Nunca', 'Às vezes', 'Frequentemente',\n",
    "    'Raramente', 'Aqui', 'Lá', 'Dentro', 'Fora', 'Longe', 'Perto', 'Acima', 'Abaixo', 'Juntos',\n",
    "    'Separadamente', 'Certamente', 'Provavelmente', 'Possivelmente', 'Claramente', 'Obviamente',\n",
    "    'Sutileza', 'Sem dúvida', 'Sem querer', 'De repente', 'Gradualmente'])\n",
    "    words.insert(insert_idx, random_word)\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_input(data):\n",
    "    phrases = []\n",
    "    for line in data.strip().split('\\n'):\n",
    "        line = line.strip()\n",
    "        if line.startswith('-'):\n",
    "            phrase = line[1:].strip()\n",
    "            phrases.append(phrase)\n",
    "    return phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spelling_errors(phrase):\n",
    "    \"\"\"\n",
    "    Introduz erros ortográficos alterando caracteres em pelo menos duas palavras aleatórias da frase.\n",
    "    \"\"\"\n",
    "    words = phrase.split()\n",
    "    words_to_modify = set()\n",
    "    \n",
    "    num_errors = min(2, len([word for word in words if len(word) > 1]))\n",
    "    \n",
    "    while len(words_to_modify) < num_errors:\n",
    "        word_idx = random.randint(0, len(words)-1)\n",
    "        word = words[word_idx]\n",
    "        if len(word) > 1:\n",
    "            words_to_modify.add(word_idx)\n",
    "    \n",
    "    for word_idx in words_to_modify:\n",
    "        word = words[word_idx]\n",
    "        char_idx = random.randint(0, len(word)-1)\n",
    "        random_char = random.choice('abcdefghijklmnopqrstuvwxyz')\n",
    "        word = word[:char_idx] + random_char + word[char_idx+1:]\n",
    "        words[word_idx] = word\n",
    "    \n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remocao_noise(phrase):\n",
    "    \"\"\"\n",
    "    Introduces removal noise by randomly deleting a word from the phrase.\n",
    "    \"\"\"\n",
    "    words = phrase.split()\n",
    "    if words:\n",
    "        remove_idx = random.randint(0, len(words)-1)\n",
    "        del words[remove_idx]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraphrase_generation(phrase):\n",
    "    \"\"\"\n",
    "    Generates paraphrases using simple transformation rules.\n",
    "    \"\"\"\n",
    "    if ' de ' in phrase:\n",
    "        parts = phrase.split(' de ')\n",
    "        if len(parts) == 2:\n",
    "            return f\"{parts[1]} com {parts[0]}\"\n",
    "\n",
    "    if ' e ' in phrase:\n",
    "        parts = phrase.split(' e ')\n",
    "        if len(parts) == 2:\n",
    "            return f\"{parts[1]} e {parts[0]}\"\n",
    "\n",
    "    if ' para ' in phrase:\n",
    "        parts = phrase.split(' para ')\n",
    "        if len(parts) == 2:\n",
    "            return f\"{parts[1]} com {parts[0]}\"\n",
    "\n",
    "    words = phrase.split()\n",
    "    if len(words) == 2:\n",
    "        return f\"{words[1]} {words[0]}\"\n",
    "\n",
    "    if ' com ' in phrase:\n",
    "        parts = phrase.split(' com ')\n",
    "        if len(parts) == 2:\n",
    "            return f\"{parts[1]} com {parts[0]}\"\n",
    "\n",
    "    if ' do ' in phrase:\n",
    "        parts = phrase.split(' do ')\n",
    "        if len(parts) == 2:\n",
    "            return f\"{parts[1]} com {parts[0]}\"\n",
    "    if ' da ' in phrase:\n",
    "        parts = phrase.split(' da ')\n",
    "        if len(parts) == 2:\n",
    "            return f\"{parts[1]} com {parts[0]}\"\n",
    "\n",
    "    if ' por ' in phrase:\n",
    "        parts = phrase.split(' por ')\n",
    "        if len(parts) == 2:\n",
    "            return f\"{parts[1]} com {parts[0]}\"\n",
    "\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraphrase_regex(phrase):\n",
    "\n",
    "    phrase = re.sub(r'\\bnão é\\b', 'não está', phrase)\n",
    "\n",
    "    phrase = re.sub(r'\\bnão foi\\b', 'não esteve', phrase)\n",
    "\n",
    "    phrase = re.sub(r'\\bpreciso de\\b', 'necessito de', phrase)\n",
    "\n",
    "    phrase = re.sub(r'\\bestá\\b', 'encontra-se', phrase)\n",
    "\n",
    "    phrase = re.sub(r'\\btem que\\b', 'precisa', phrase)\n",
    "\n",
    "    phrase = re.sub(r'\\bvai ser\\b', 'será', phrase)\n",
    "\n",
    "    phrase = re.sub(r'\\bde novo\\b', 'novamente', phrase)\n",
    "\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraphrase_syntax_tree(phrase):\n",
    "    \"\"\"\n",
    "    Generates paraphrases by transforming syntax trees.\n",
    "    \"\"\"\n",
    "    doc = nlp(phrase)\n",
    "    tokens = [token.text for token in doc]\n",
    "    if len(tokens) >= 3:\n",
    "        tokens[0], tokens[2] = tokens[2], tokens[0]\n",
    "        return ' '.join(tokens)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def back_translation_api(phrase, src_lang='pt', intermediate_lang='en'):\n",
    "\n",
    "    translator = Translator()\n",
    "    \n",
    "    try:\n",
    "        # Traduzir do idioma de origem para o idioma intermediário\n",
    "        translated = translator.translate(phrase, src=src_lang, dest=intermediate_lang)\n",
    "        intermediate_text = translated.text\n",
    "        \n",
    "        # Traduzir de volta para o idioma de origem\n",
    "        back_translated = translator.translate(intermediate_text, src=intermediate_lang, dest=src_lang)\n",
    "        final_text = back_translated.text\n",
    "        print(final_text)\n",
    "        \n",
    "        return final_text\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Ocorreu um erro durante a retrotradução:\", e)\n",
    "        return phrase  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '''\n",
    "    #insert here you data to data aug\n",
    "\n",
    "'''\n",
    "\n",
    "phrases = parse_input(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phrase in phrases:\n",
    "    print(insercao_noise(phrase))\n",
    "    print(remocao_noise(phrase))\n",
    "    print(spelling_errors(phrase))\n",
    "    print(sinonimo(phrase))\n",
    "    print(paraphrase_generation(phrase))\n",
    "    print(paraphrase_regex(phrase))\n",
    "    print(paraphrase_syntax_tree(phrase))\n",
    "    print(back_translation_api(phrase))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
