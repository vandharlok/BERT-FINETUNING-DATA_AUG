{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We gonna use 3 differentes models to test our data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### They are \n",
    "##### - multi-qa-distilbert-cos-v1 (SentenceTransformer)\n",
    "##### - sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 (SentenceTransformer)\n",
    "##### - cross-encoder/ms-marco-MiniLM-L-6-v2 (CrossEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vanderson/miniconda3/envs/bert/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import CrossEncoder\n",
    "import torch\n",
    "model = SentenceTransformer(\"multi-qa-distilbert-cos-v1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o modelo sentence-transformers multilíngue\n",
    "model_LM = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_cross = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\", default_activation_function=torch.nn.Sigmoid(),max_length=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8022, 0.7465, 0.8904, 0.8691, 0.8514, 0.5310, 0.7641]])\n"
     ]
    }
   ],
   "source": [
    "##Using the first model (multi_qa) as the model is not trained in multilingual\n",
    "## and we want to use to portuguese phrases, i will have to translate to use this model\n",
    "passage_embeddings=model.encode([\n",
    "    \"cancelar consulta\",\n",
    "   \" cancelar uma consulta\",\n",
    "    \"Quero cancelar a consulta\",\n",
    "   \" Como faz para cancelar a consulta\",\n",
    "   \" Preciso cancelar a consulta\",\n",
    "    \"Gostaria de desmarcar a consulta\",\n",
    "   \" Como faço para cancelar a consulta que marquei\"\n",
    "])\n",
    "query_embedding=model.encode(\"quero cancelar minha consulta\")\n",
    "similarity=model.similarity(query_embedding,passage_embeddings)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9259, 0.9335, 0.9778, 0.9416, 0.9662, 0.9486, 0.9275]])\n"
     ]
    }
   ],
   "source": [
    "##As we can see, the scores values to english phrases are much higher\n",
    "passage_embeddings=model.encode([\n",
    "    \"cancel appointment\", \n",
    "    \"cancel an appointment\", \n",
    "    \"I want to cancel the appointment\", \n",
    "    \"How do I cancel the appointment\", \n",
    "    \"I need to cancel the appointment\", \n",
    "    \"I would like to cancel the appointment\", \n",
    "    \"How do I cancel the appointment I made\"\n",
    "])\n",
    "query_embedding=model.encode(\"I want to cancel my appointment\")\n",
    "similarity=model.similarity(query_embedding,passage_embeddings)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6398, 0.8695, 0.7883, 0.3477, 0.7496, 0.6453, 0.6793, 0.7133]])\n"
     ]
    }
   ],
   "source": [
    "### USING THE SECOND MODEL, MULTILINGUAL\n",
    "### Testing with portuguese phrases\n",
    "query_embedding=model_LM.encode(\"Gostaria de marcar uma consulta\")\n",
    "# Exemplo de uso com frases em português\n",
    "passage_embeddings=model_LM.encode([\n",
    "    \"marcar consulta com o psicologo\",\n",
    "    \"marcar uma consulta\",\n",
    "    \"como agendo uma consulta\",\n",
    "    \"como agendo um horario com voces\",\n",
    "    \"quero marcar uma consulta com voces\",\n",
    "    \"como faco para marcar uma consulta com voces\",\n",
    "    \"Como posso reservar um horário para consulta\",\n",
    "    \"É possível marcar um atendimento\"\n",
    "])\n",
    "similarity=model_LM.similarity(query_embedding,passage_embeddings)\n",
    "\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5216, 0.8320, 0.7826, 0.7398, 0.7807, 0.7398, 0.9449, 0.7662]])\n"
     ]
    }
   ],
   "source": [
    "#### For english phrases, we do not see much difference is scores\n",
    "query_embedding=model_LM.encode(\"I want to book an appointment\")\n",
    "passage_embeddings=model_LM.encode([\n",
    "\"book an appointment with a psychologist\",\n",
    "\"book an appointment\",\n",
    "\"how do I schedule an appointment\",\n",
    "\"how do I schedule an appointment with you\",\n",
    "\"I want to schedule an appointment with you\",\n",
    "\"how do I schedule an appointment with you\",\n",
    "\"How can I book an appointment\",\n",
    "\"Is it possible to schedule an appointment\"\n",
    "])\n",
    "similarity=model_LM.similarity(query_embedding,passage_embeddings)\n",
    "\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5282, 0.9095, 0.7804, 0.7978, 0.8564, 0.7978, 0.9507, 0.7263]])\n"
     ]
    }
   ],
   "source": [
    "### Lets compare the scores with the first model\n",
    "query_embedding=model.encode(\"I want to book an appointment\")\n",
    "passage_embeddings=model.encode([\n",
    "\"book an appointment with a psychologist\",\n",
    "\"book an appointment\",\n",
    "\"how do I schedule an appointment\",\n",
    "\"how do I schedule an appointment with you\",\n",
    "\"I want to schedule an appointment with you\",\n",
    "\"how do I schedule an appointment with you\",\n",
    "\"How can I book an appointment\",\n",
    "\"Is it possible to schedule an appointment\"\n",
    "])\n",
    "similarity=model.similarity(query_embedding,passage_embeddings)\n",
    "\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### the first model obtained higher scores for English sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9947903  0.01229856 0.01899222 0.991536   0.90968424 0.04460678]\n"
     ]
    }
   ],
   "source": [
    "### Lets test the cross encoder model\n",
    "scores = model_cross.predict([\n",
    "    (\"I want to book an appointment\", \"book an appointment\"),\n",
    "    (\"I want to book an appointment\", \"how do I schedule an appointment\"),\n",
    "    (\"I want to book an appointment\", \"how do I schedule an appointment with you\"),\n",
    "    (\"I want to book an appointment\", \"I want to schedule an appointment with you\"),\n",
    "    (\"I want to book an appointment\", \"How can I book an appointment\"),\n",
    "    (\"I want to book an appointment\", \"Is it possible to schedule an appointment\"),\n",
    "\n",
    "       \n",
    "])\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This cross encoder model does not handle synonymous words very well, so it will not be very useful for data augmentation, since the intention is to expand the database with synonyms and similar words, maintaining the meaning of the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But, how cross encoder detect a high level of score with similar sentences, we are gonna use to detect duplicates or too similar phrases in our dataset, to avoid too much similar data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
